<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Divvunspell—Finite-State Spell-Checking and Correction on Modern Platforms</title>
<!--Generated on Thu Oct 30 15:45:49 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="../latexml/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../latexml/ltx-article.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Divvunspell—Finite-State Spell-Checking and Correction on Modern Platforms</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Flammie A Pirinen 
<br class="ltx_break">Divvun 
<br class="ltx_break">UiT—Norgga árktalaš universitehta 
<br class="ltx_break">Tromsø
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Norway 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">flammie.pirinen@uit.no</span> 
<br class="ltx_break">
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sjur Nørstebø Moshagen 
<br class="ltx_break">Divvun 
<br class="ltx_break">UiT—Norgga árktalaš universitehta 
<br class="ltx_break">Tromsø
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Norway 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">sjur.n.moshagen@uit.no</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
    
<p class="ltx_p">Spell-checking and correction is one of the key applications of natural
language support. Historically, for the biggest, less morphologically
complex languages, spell-checking and correction could be implemented by
relatively simple means; however, for morphologically complex and
low-resource languages, the solutions were often suboptimal. Finite-state
methods are the state of the art in rule-based natural language processing
and also for spell-checking and correction they have been effectively used.
In this article, we show some recent developments of a finite-state
spell-checker implementation that works with modern operating systems and
platforms.</p>
  
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Spell-checking and correction is one of the most basic and most important
applications of natural language processing for standardised, written languages.
A spell-checker works as a tool for all of the writers of the language, ensuring
that most of the texts written follow a norm that is enforced by the tool. This
has enormous significance for the text production in the language, which in turn
is becoming more and more important in the era of large language models. A
large language model is built on huge quantities of texts written by humans, and
an underlying expectation is that the majority of the text is written in a
standard, norm-abiding language form.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Traditionally spell-checkers have been readily available for morphologically
simple languages but have had more limited success for more morphologically
complex languages; for example, to this day hunspell is popularly used for a lot
of platforms on a computer as a default spell-checker engine. Hunspell itself
being developed because previous systems were insufficient for Hungarian
morphology, it moreover is limited for other morphologically complex languages.
Another approach to spell-checking that is popular in contemporary systems is
data-based, either statistical or neural network, this is what many of the
autocorrect and autocomplete style models are based on. This, on the other
hand, limits the low-resourced languages out of the equation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">The main contribution of this article is recent developments in our
implementation of <span class="ltx_text ltx_font_italic">finite-state spell-checking</span>, as well as relevant
tooling and automation. Finite-state spell-checking works for morphologically
complex languages and does not necessarily require any training data, making it
suitable for low-resource use cases. One emphasis of this article is the
developments related to full end-user use case of the method that the software
is not merely an academic experiment but a product that can be installed and
used by the language users. For this purpose, we have developed automated
evaluation methodology as well as systems for automatically distributing the new
changes to end-users.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">Following the recent trends of the language technology, that is the
break-throughs of the large language models and neural networks, we evaluate our
system and compare it to an out of the box neural network in a basic
spell-checking and correction task. While the evaluation we perform here is
quite rudimentary as a neural network application, it builds towards the
research question of: how and to which extents and in which parts of a
spell-checking and correcting system shall the large language models be used in
hybrid with existing finite-state and rule-based solutions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Spell-checking and correction is an application of natural language processing
that has been studied since the 1950’s. The earliest models worked in practice
based on static lists of correctly written word-forms to check against, then
slowly adding support for morphological processes as larger vocabularies and
more morphologically complex languages were implemented. The most widely spread
versions of the spell-checkers used in personal computers are commonly known as
<span class="ltx_text ltx_font_typewriter">*spell</span> software, from original SPELL to ispell, aspell, myspell,
hunspell and nuspell. Still, these have been difficult to adapt for
morphologically rich languages, so for specific languages softwares like
zemberek for Turkish and hspell for Hebrew have been developed</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">Parallel to dictionary-based spell-checkers there has been statistical
approaches to spell-checking. This is based on learning a language model from
large correctly written texts, one of the most influential models here
is <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">norvig2010howto</span>]</cite>. This line of models is usually a basis in most of
the mobile auto-complete and autocorrect style systems, nowadays likely based on
generative neural network models.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">The most basic tool for modeling errors is based on the invention of edit
distance, where the errors are modeled as a combination of missing a letter,
adding an extra letter, using a wrong letter, or swapping two adjacent letters,
first introduced by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">levenshtein1966binary</span>]</cite>. Other common ideas that have
been used include listing common confusables altogether, trying to map phonemic
errors to the writing system various ways, and weighing the mistakes made on a
keyboard by the keyboard layout.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">One of the most popular ways of handling word-forms of morphologically complex
languages is Finite State Morphology <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">beesley2003finite</span>]</cite>, this is often
considered the state of the art in handling rule-based language modeling of
morphologically context low-resourced languages to this date. The finite-state
formulation of spell checking with statistically trained language and error
models has been researched by <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pirinen2014state</span>]</cite>. This type of models is
also used by the spell-checking and correction solution we are presenting in
this article.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">Finite-state spell-checking is based on using finite-state automata to model
both the correctly spelled words (language model) and mapping of the
misspellings from incorrect forms to correct word-forms. In finite-state format
this means that there is an automaton that accepts the correctly spelled
word-forms and does not accept incorrectly spelled word-forms, and another
two-tape automaton that can relate incorrectly spelled word-forms to correctly
spelled word-forms. The automata can be weighted and thus give an ordering to
correction suggestions as well as likelihoods for the words of the languages in
general. This model has been introduced by at least <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pirinen2010finite</span>]</cite>,
and the software introduced here is based on the same finite-state formulation.
For language models we have used freely available open source finite-state
models from the GiellaLT infrastructure <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pirinen2023giellalt</span>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">The <span class="ltx_text ltx_font_italic">divvunspell<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>
              <span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright">1</span></span>
              
              
              
            <a href="https://github.com/divvun/divvunspell" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/divvun/divvunspell</a></span></span></span></span>
software we introduce in this article is implemented in the Rust programming
language and has bindings and implementations for modern operating systems and
mobile platforms: macOS systemwide, Windows systemwide and in MS Office,
LibreOffice on all desktop systems, and in iOS and Android keyboard apps. There
is also a REST API for web-based
clients<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>
            <span class="ltx_tag ltx_tag_note">2</span>
            
            
            
          <a href="https://api-giellalt.uit.no/speller/XX" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api-giellalt.uit.no/speller/XX</a>, where XX is the
ISO 639 language code.</span></span></span>. We have implemented some basic improvements to the
engineering and efficiency as well as correctness of the software. The
published version is both light-weight and fast enough to be used as an
interactive spelling checker on average end-users’ mobile platforms. We have
fine-tuned the error-correction algorithm with adjustable weights in the errors
made in word-initial, word-medial and word-final positions separately; in the
the current version a spelling error in the first or last letter of the word
adds triple the weight of an error in the mid-word unless configured
otherwise.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>
            <span class="ltx_tag ltx_tag_note">3</span>
            
            
            
          the actual and up-to-date implementation of the algorithm
can be found on GitHub.</span></span></span> We have also developed an automated evaluation software
for the spell-checking software that can ensure the quality of the
spell-checking models does not degrade, as well as a continuous integration and
deployment system that can distribute the models to the end users when the
dictionaries or grammars of language models are updated, as long as the quality
of the spell-checker has not deteriorated. The automatic evaluation tools are
available on the github repo of <span class="ltx_text ltx_font_italic">divvunspell</span> and their integration to
language development infrastructures can be found on the actual language data
repositories<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>
            <span class="ltx_tag ltx_tag_note">4</span>
            
            
            
          <a href="https://github.com/giellalt/template-language-und" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/giellalt/template-language-und</a>,
to be refactored into <a href="https://github.com/divvun/actions/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/divvun/actions/</a></span></span></span>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">We experiment with a popular out-of-the-box large language model that is
available for most users free of charge via a chat interface. <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>
            <span class="ltx_tag ltx_tag_note">5</span>
            
            
            
          At the
time of writing we had access to a version of ChatGPT-4o.</span></span></span> We do not perform any
in-context learning or retrieval augmented generation, this is an initial
experiment towards potential hybrid models of finite state and neural models of
spell-checking and correction.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="2024-12-20-152333_645x492_scrot.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of LLM-based spell-checking and correction</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">We performed a small experiment to verify the working of our system and to see
how well the out-of-the-box neural network works on this task. We are testing
with a real-world error corpus of Finnish word-forms—50 correctly written
words and 50 spelling mistakes found in a large corpus—by picking up
non-words and correcting them manually. Finnish is a morphologically complex
language with medium-to-high resources. The results are in
Table <a href="#S4.T1" title="Table 1 ‣ 4 Results ‣ Divvunspell—Finite-State Spell-Checking and Correction on Modern Platforms" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The overall quality of both spelling checking and
correction is lower in the LLM-based system than it is for the rule-based system
but it still manages to provide correct suggestions almost as often as
rule-based system does.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row">System</th>
<td class="ltx_td ltx_align_right">1st</td>
<td class="ltx_td ltx_align_right">Any</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row">FST</th>
<td class="ltx_td ltx_align_right">70 %</td>
<td class="ltx_td ltx_align_right">88 %</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row">LLM</th>
<td class="ltx_td ltx_align_right">50 %</td>
<td class="ltx_td ltx_align_right">85 %</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Automatic evaluation of spelling correction </figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">We have shown a software that brings the spell-checker to end-users on mobile
and desktop platforms and updates automatically when linguistic data gets
developed. However, especially on mobile platforms but also increasingly on
desktop, the spell-checking has been shifting towards a sub-function of a text
prediction subsystem, e.g. autocomplete / autocorrect. It would be interesting
future work to study possibility of such a system for morphologically complex
and low-resource languages.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p">We only performed cursory experiments to ensure that our system works within
specified parametres, the system should be functionally similar as the system
evaluated by <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">pirinen2014state</span></cite> in their larger survey. We also performed
the same experiment on an out-of-the-box, not fine-tuned and not prompted,
re-inforced or otherwise context augmented neural network, mainly to find out
their current level of quality and possible future modes of hybridisation. From
the results it seems that the LLM-based systems are approaching the quality of
rule-based system in terms of overall suggestions but if you concentrate on
suggestion quality, it is still not comparable. More importantly, when doing a
manual error evaluation, we find some examples where rule-based system is more
restricted towards edit distance type error modeling, whereas LLM tends to
suggest patterns of related word-forms of a same word.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p">One of the requirements of an end-user system in spell-checking and correction
is high precision in detecting errors, the end-users tend to react very
negatively of spell-checking systems that red-underline words they know are
correctly written. Secondly the suggestions need to be reasonable first and
foremost. Both of these aspects are relatively harder to get right with LLM
solutions of today, however, there are some indications that LLMs can be more
creative in error modelling, and especially when the spelling-correctors are set
in the automatic text prediction context, they have been succesful. Ideally we
could foresee a future system that combines the high precision of rule-based
spell-checking with creative prediction of an generative AI as a potential
spell-checking system.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Summary</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">We have demonstrated a spell-checking and correction system based on
finite-state technology that works on end-user systems including desktop office
applications and mobile phones. We tested an LLM-based approach to the same
task to see where they stand at and if they could be included in the system but
at the moment they are still far enough from end-user quality to be included
as-is.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">The LLM test is based on one version of a closed commercial system and is not
reproducible. The test is only intended to give an impression of initial
usability of such systems, and for that reason we also have not included
extensive descriptions of the parameters, prompts and version specifics. The
prompt used is given in the Figure <a href="#Sx1.F2" title="Figure 2 ‣ Limitations ‣ Divvunspell—Finite-State Spell-Checking and Correction on Modern Platforms" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="Sx1.F2" class="ltx_figure"><pre class="ltx_verbatim ltx_font_typewriter" style="font-size:70%;">
You are a spell-checker for Finnish language,
you will be given a list of word-forms and you
should answer with a list of the word-forms,
then suggested corrections for example:
    rahhaaΨrahaaΨrahkaa
If a word is already correct,
the first suggestion should be
the same as the input word:
    plleΨplle
    
</pre>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>ChatGPT prompt for spell-checking.</figcaption>
</figure>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p class="ltx_p">The data annotation and human evaluation was performed by article authors and
colleagues; no unpaid annotators were used. The LLMs use significant amount of
water and electricity and we have made an effort to minimise unnecessary overuse
of LLMs.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="bib.L1" class="ltx_biblist">
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 30 15:45:49 2025 by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>
</body>
</html>
