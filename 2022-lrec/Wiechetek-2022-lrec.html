<!DOCTYPE html><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch  1  footnote 1  1  footnote 1  LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/</title>
<!--Generated on Tue Jun 14 13:50:15 2022 by LaTeXML (version 0.8.6) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="../latexml/LaTeXML.css" type="text/css">
<link rel="stylesheet" href="../latexml/ltx-article.css" type="text/css">
<link rel="stylesheet" href="ltx-listings.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Unmasking the Myth of Effortless Big Data — 
<br class="ltx_break">Making an Open Source
Multilingual Infrastructure and Building Language Resources from
Scratch<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>
        <span class="ltx_tag ltx_tag_note">1</span>
        
        
        
      LREC is open access with CC-BY-NC licence. Print
version can be found at <a href="https:/2022.lrec-conf.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https:/2022.lrec-conf.org/</a></span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Linda Wiechetek
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Katri Hiovain-Asikainen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Inga Lill Sigga Mikkelsen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sjur N. Moshagen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Flammie A. Pirinen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Trond Trosterud
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Børre Gaup
<br class="ltx_break">Department of Language and Culture, UiT the Arctic University of Norway 
<br class="ltx_break">giellalt@uit.no
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
    
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Machine learning</span> (ML) approaches have dominated <span class="ltx_text ltx_font_italic">Natural
Language Processing</span> (NLP) during the last two decades. From machine
translation and speech technology, machine learning tools are now also in use
for spellchecking and grammar checking, with a blurry distinction between the
two.</p>
    
<p class="ltx_p">We unmask the myth of effortless big data by illuminating the efforts and time
that lay behind building a multi-purpose corpus with regard to collecting,
marking up and building from scratch. We also discuss what kind of language
technology tools minority language communities actually need, and to what extent
the dominating paradigm has been able to deliver these tools. In this context
we present our alternative to corpus-based language technology—knowledge-based
language technology—and we show how this approach can provide
language technology solutions for languages being outside the reach of machine
learning procedures. We present a stable and mature infrastructure
(<span class="ltx_text ltx_font_italic">GiellaLT</span>) containing more than hundred languages and building a number
of language technology tools that are useful for language communities. 
<br class="ltx_break">
<br class="ltx_break"><span class="ltx_text ltx_font_italic">keywords:</span> infrastructure, corpus, text processing, minority languages,
finite state technology, knowledge-based nlp, grammar checking, TTS, ASR, speech
technology, spellchecking</p>
  
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">During the last two decades, i.e. early 2000s, machine learning approaches have
dominated the field of <span class="ltx_text ltx_font_italic">natural language processing</span> (NLP). The
philosophy has been to have machines learn behaviour from large corpora, thereby
offering speech technology, machine translation and spelling and grammar
checking.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">For at least 3/4 of the world’s languages, this is bad news. They have less than
20,000 speakers, and even with a school system teaching mother tongue literacy
and a language policy encouraging publishing, such small populations would have
a hard time producing enough text to be able to model the language in a reliable
way using the dominating NLP paradigm. On top of that, weak literary traditions
give rise to corpora too unreliable to be able to function as a model for NLP
tools.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">From the reactions we get on our work in the current academic NLP community
contexts, we experience an absence of understanding for why we choose to work
rule-based, despite our explanations of unavailable noise-free data. There seems
to be the idea that big data comes for free. In addition, since most of the
work within the dominating methodology is done on morphologically simple
languages, there seems to be a general lack of understanding of the
methodologies and technologies needed to work efficiently with polysynthetic and
other morphologically complex languages.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">This article has a clear answer to the big data question — corpus data does
not come for free, as illustrated in the three test cases we present. Building
corpora requires proficient writers or speakers of the language. In addition, it
requires proof-readers, translators and experts who can mark up the texts with
regard to errors or other traits of the text. While these may be available for
some languages before developing language tools, many languages need to build
them from scratch.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">However, there is a way to produce the NLP tools needed by the language
community without Big Data. We show how a set of knowledge-based methods is able
to analyse and generate morphologically complex languages reliably, as well as a
language-independent infrastructure that makes it possible to share
developmental costs among the languages involved.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">We have within 20 years built language resources for several Sámi languages from
scratch—this includes lexica, morphological and syntactic analysers. Even
though we had a number of non-digital resources available, these were far from
exhaustive. This means that our work also included normative discussions,
requests and suggestions to the language normative organs, error
classifications, grammatical descriptions of phenomena not included in grammar
books. In several cases, these phenomena needed traditional linguistic research.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">We argue that both a functioning literacy and thereby also corpus-based
approaches are dependent upon rule-based tools of the type produced via our
approach.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>What does the language community need?</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">At present, several minority language communities with a weak literary tradition
try to strengthen the position of the language in society. In doing so, they
find themselves in a situation lacking the infrastructure needed to do so,
infrastructure that majority language speakers take for granted.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p class="ltx_p">Looking at the writing process, there must be a keyboard layout. Most
orthographies contain letters outside the A-Z (or Cyrillic А-Я) range, these
letters must be placed on the keyboard in ergonomically sound positions. Layouts
should be easy to install on the operating systems on both computers and mobile
devices.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p">In order to produce text with a consistent spelling in an efficient way, the
language community will need a spelling checker. Since there are few proofread
texts, a spelling checker can not be made by learning from an existing corpus.
Not only will the existing corpora be too small, they will typically also be too
unreliable. With a weak literary tradition, text often deviates from the norm,
and the existing body of text thus can not be taken as a substitute for an
explicit norm.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p class="ltx_p">Language communities wanting to strengthen their language do not start from
scratch. In practice, the languages of such communities have already been
described to a certain extent. Given the present state of linguistic typology
research, there will in all relevant cases be scholars devoted to the language,
who have made dictionaries covering the core vocabulary and a basic grammar. In
order to teach the language to new speakers and to publish texts, the language
will still need a practical orthography, an orthography with design principles
radically different from the ones used by philologists and typologists. Making a
good practical orthography and rewriting the philologists’ grammars and
dictionaries by using this orthography is at the core of the language planning
process.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p class="ltx_p">Machine translation into a minority language is of no use when the output is
unreliable and the language community bilingual, thus in a position to choose
the majority language original instead. Translation from the minority language
is of no use if there is no monolingual text to translate.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p class="ltx_p">Based upon experience with around 50 language models (cf.
<a href="https://giellalt.github.io/LanguageModels.html" title="" class="ltx_ref ltx_href ltx_font_italic">giellalt.github.io</a>)
we found that if the lexicon is electronically available and the grammatical
structure reasonably clear, a grammatical model covering around 80</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Related work</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p">Several studies discuss key aspects of the infrastructure presented here,
e.g. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib210" title="Building language technology infrastructures to support a collaborative approach to language resource building" class="ltx_ref">25</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="Building an open-source development infrastructure for language technology projects" class="ltx_ref">22</a>]</cite>. We are not
aware of too many similar open source infrastructures that contain both the same
amount of languages and different end user applications that actually work. One
example is the rule-based machine-translation system
Apertium <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="Recent advances in Apertium, a free/open-source rule-based machine translation platform for low-resource languages" class="ltx_ref">16</a>]</cite> that hosts repositories for language resources
for 51 machine translators. In addition to containing machine translation pairs
in use in different practical applications, the language models underlying them
may also be used for a wide range of applications. As a part of the
<span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure work we have made a pipeline for including our
language models in the <span class="ltx_text ltx_font_italic">Apertium</span> pipeline, our MT programs are thus made
using the <span class="ltx_text ltx_font_italic">Apertium</span> formalism.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">The producers of statistical and corpus-based models have also started to gather
their data and models into larger multilingual repositories. If we try to draw
parallels, for example within the recent neural models, one could compare our
repository to the likes of
<a href="https://huggingface.co" title="" class="ltx_ref ltx_href ltx_font_italic">huggingface.co</a> that hosts a repository
of language models and APIs to access them <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib294" title="Transformers: state-of-the-art natural language processing" class="ltx_ref">34</a>]</cite>. However,
they are still mainly targeting English and a handful of well-resourced
languages, and while a number of lower-resourced languages are provided with
models and data, the data seems to be very limited. In speech technology and
corpora, there is also the common voice project from Mozilla that gathers speech
resources for multiple languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="Common voice: a massively-multilingual speech corpus" class="ltx_ref">5</a>]</cite>, and eventually
provides spoken language models.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>A multilingual infrastructure from scratch</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">In this article, we will assume that the basic language planning work has been
done and that there is a practical orthography and access to the lexicon of the
language in machine-readable format and a basic grammar. This description holds
for a large group of languages that still have no language technology tools in
place.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>The <span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">The foundation for the work presented in this article is the multilingual
infrastructure <a href="https://github.com/giellalt" title="" class="ltx_ref ltx_href ltx_font_italic">GiellaLT</a>, which
includes numerous languages — 130 altogether — that have little or no data,
a rare case in the NLP world.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">Everything produced in the <span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure is under free and
open licences and freely available. The corpora are available with free
licensing where possible. The infrastructure is split code-wise in three GitHub
organisations: <a href="https://github.com/giellalt" title="" class="ltx_ref ltx_href ltx_font_italic">GiellaLT</a> containing
the language data for each language,
<a href="https://github.com/divvun" title="" class="ltx_ref ltx_href ltx_font_italic">Divvun</a> containing language
independent code for the infrastructure, and
<a href="https://github.com/giellatekno" title="" class="ltx_ref ltx_href ltx_font_italic">Giellatekno</a> for corpus
infrastructure. End user tools served by the Divvun group are at
<a href="https://divvun.no" title="" class="ltx_ref ltx_href ltx_font_italic">divvun.no</a> &amp;
<a href="https://divvun.org" title="" class="ltx_ref ltx_href ltx_font_italic">divvun.org</a>, and tools served by the
Giellatekno group at
<a href="https://giellatekno.uit.no" title="" class="ltx_ref ltx_href ltx_font_italic">giellatekno.uit.no</a>, both at
<span class="ltx_text ltx_font_italic">UiT—Norway’s Arctic University</span>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">We build systems that include lexical data as well as rules governing
morphophonology, syntax and semantics as well as a number of application
specific information, e.g. grammatical rules for grammar checking, phonetic
rules for <span class="ltx_text ltx_font_italic">Text-To-Speech</span> (TTS) and so forth.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p class="ltx_p">The language-independent work is currently done within the infrastructure, the
language-independent features and updates that are relevant to all languages are
semi-automatically merged as they are developed. To ensure that language
independent and common features and updates do not destroy existing language
data or use case, we enforce a rigorous continuous integration based testing
regime. The current system for testing is a combination of our long-term
investment in testing within the infrastructure locally for
developers—combined with modern automatic testing currently supplied by
<a href="https://github.com/divvun/actions" title="" class="ltx_ref ltx_href">GitHub actions</a>.
</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p">Another part of the <span class="ltx_text ltx_font_italic">GiellaLT</span> philosophy is that of reusable and
multi-purposeful resources, cf. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="Reusing grammatical resources for new languages" class="ltx_ref">3</a>]</cite>. This is
true for all of our work, from corpus collection to cross-lingual cooperation.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p class="ltx_p">Despite the lack of data, there are high-level tools in <span class="ltx_text ltx_font_italic">GiellaLT</span> such
as machine translation, TTS, spelling and grammar checkers and more, that have
been very well received in the language communities. This would not have been
possible without first developing basic tools such as keyboards, morphological
analysers and spelling checkers.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Keyboards</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">To be able to type and write a language, you need a keyboard. Using the tool
<a href="https://github.com/divvun/kbdgen" title="" class="ltx_ref ltx_href ltx_font_typewriter">kbdgen</a>, one can easily specify
a keyboard layout in a <a href="https://yaml.org" title="" class="ltx_ref ltx_href ltx_font_italic">YAML</a> file, mimicking
the actual layout of the keyboard. The listing below shows the definition of the
Android mobile keyboard layout for Lule Sámi. The <span class="ltx_text ltx_font_typewriter">kbdgen</span> tool takes
this definition and a bit of metadata, combines it with code for an Android
keyboard app, compiles everything, signs the built artefact and uploads it to
the Google Play Store, ready for testing.
</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<div class="ltx_listing ltx_lstlisting ltx_framed_rectangle ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,bW9kZXM6CiAgYW5kcm9pZDoKICAgIGRlZmF1bHQ6IHwKICAgICAgw6EgdyBlIHIgdCB5IHUgaSBvIHAgw6UKICAgICAgYSBzIGQgZiBnIGggaiBrIGwgw7ggw6YKICAgICAgICAgeiB4IGMgdiBiIG4gbSDFiw==" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">modes</span><span class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">  </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">android</span><span class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">    </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">default</span><span class="ltx_text ltx_font_typewriter" style="font-size:80%;">:</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_font_typewriter" style="font-size:80%;">|</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">      </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">á</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">w</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">e</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">r</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">t</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">y</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">u</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">o</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">p</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">å</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">      </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">a</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">s</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">d</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">f</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">g</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">h</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">j</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">k</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">l</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">ø</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">æ</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;">         </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">z</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">x</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">c</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">v</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">b</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">n</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" style="font-size:80%;">m</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" style="font-size:80%;"> </span><span class="ltx_text ltx_font_typewriter" style="font-size:80%;">ŋ</span>
</div>
</div>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p">The tool supports generating keyboard apps or installer packages for Android,
iOS, macOS, Windows, Linux (X11 and m17n) and Chrome OS. There is also
experimental support for generating
<a href="https://cldr.unicode.org" title="" class="ltx_ref ltx_href"><span class="ltx_text ltx_font_italic">Common Language Data Repository</span> (CLDR)</a>
XML files, <span class="ltx_text ltx_font_italic">Scalable Vector Graphics</span> (SVG) files for fast layout
debugging, and finite state transducers for neighbour key mistyping error
models. The Windows installer includes a tool to register unknown languages, so
that even languages never seen on a Windows computer will be properly
registered, and thus making it ready to support proofing tools and other
language processing tools.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Morphological analysers</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">The foundation for all linguistic processing in the <span class="ltx_text ltx_font_italic">GiellaLT</span>
infrastructure is the morphological analyser, built using formalisms from Xerox:
<span class="ltx_text ltx_font_typewriter">lexc</span>, <span class="ltx_text ltx_font_typewriter">xfst</span> and optionally <span class="ltx_text ltx_font_typewriter">twolc</span>. From these source
files, the infrastructure creates ¸<span class="ltx_text ltx_font_italic">finite state transducers</span> (FST’s)
using one of three supported FST compilers: Xerox
tools <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="Finite state morphology" class="ltx_ref">6</a>]</cite>,
<a href="https://hfst.github.io" title="" class="ltx_ref ltx_href ltx_font_italic">HFST</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="Hfst—a system for creating nlp tools" class="ltx_ref">18</a>]</cite>, or
Foma <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="Foma: a finite-state compiler and library" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p">All language models are written as rule-based, full form lexicons with explicit
morphological descriptions and morphophonological alternations. This makes it
possible to create language models for any language, including minority and
indigenous languages with no digital presence, as long as there is cooperation
with the language community and native speakers.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p">Support for multiple usages and reuse of the same lexical data is added through
analyser tags, so that the compiled FST can be filtered and manipulated to fit a
specific usage scenario.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Morphological and syntactic disambiguation and tagging</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p">All higher-order linguistic processing is done using the VISLCG3
(<a href="http://visl.sdu.dk" title="" class="ltx_ref ltx_href ltx_font_italic">visl.sdu.dk</a>)
implementation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="Constraint grammar manual: 3rd version of the CG formalism variant" class="ltx_ref">7</a>]</cite> of Constraint
Grammar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="Constraint grammar as a framework for parsing unrestricted text" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p class="ltx_p">It has over the years proven both robust, fast and flexible, allowing rule-based
morphological disambiguation, as well as syntactic and semantic tagging, cf.
Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Morphological and syntactic disambiguation and tagging ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. It has also successfully been applied in high-quality
grammar checker applications and machine translation systems, and is often used
to create the reference tagged corpus used to train machine learning models.
Ambiguity in the Sámi languages is mostly based on homonymy between
morphological forms of the same part of speech, and less on PoS homonymy between
uninflected lemmata.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r" colspan="2"><span class="ltx_text ltx_font_bold">North Sámi</span></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r" colspan="2"><span class="ltx_text ltx_font_bold">Lule Sámi</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_th ltx_th_row"></th>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Prec</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Recall</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Prec</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_bold">Recall</span></td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row">
<span class="ltx_ERROR undefined">\toprule</span><span class="ltx_text ltx_font_bold">PoS</span>
</th>
<td class="ltx_td ltx_align_center">0.99</td>
<td class="ltx_td ltx_align_center">0.99</td>
<td class="ltx_td ltx_align_center">0.94</td>
<td class="ltx_td ltx_align_center">0.97</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row"><span class="ltx_text ltx_font_bold">morph. dis.</span></th>
<td class="ltx_td ltx_align_center">0.93</td>
<td class="ltx_td ltx_align_center">0.95</td>
<td class="ltx_td ltx_align_center">0.83</td>
<td class="ltx_td ltx_align_center">0.94</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row"><span class="ltx_text ltx_font_bold">dependencies</span></th>
<td class="ltx_td ltx_align_center">1</td>
<td class="ltx_td ltx_align_center">1</td>
<td class="ltx_td ltx_align_center">1</td>
<td class="ltx_td ltx_align_center">1</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row"><span class="ltx_ERROR undefined">\bottomrule</span></th>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>North and Lule Sámi analysers.</figcaption>
</figure>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Tokenisers</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p class="ltx_p">Tokenisation is based on an FST model initially presented by
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="Beyond morphology: pattern matching with fst" class="ltx_ref">14</a>]</cite> in the Xerox tool <span class="ltx_text ltx_font_typewriter">pmatch</span>. The resulting
FST is applied using <span class="ltx_text ltx_font_typewriter">hfst-tokenise</span>. The basic idea is to use an FST as
a pattern matching tool for natural languages, and add markup to the input text
for matching patterns. The FST is used as a tokeniser in a left-to-right,
longest-match manner. The tokeniser performs tokenisation and analysis in one
go and can handle both known and out-of-vocabulary items. Secondly, the
formalism has been extended with explicit backtracking functionality, to allow
for multiple tokenisations.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p class="ltx_p">The output of ambiguous tokens is disambiguated using linguistic rules with
VISLCG3 to specify the correct tokenisation given the context and the available
linguistic analyses. This makes it possible to achieve near-perfect
tokenisation. In our tokenisation, sentence boundary detection is treated as a
special case of ambiguous tokenisation, and solved in the same way, approaching
near-perfect sentence boundary identification, cf. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib286" title="Seeing more than whitespace — tokenisation and disambiguation in a North Sámi grammar checker" class="ltx_ref">32</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Spelling checkers</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p class="ltx_p">As mentioned briefly above in Section <a href="#S3.SS3" title="3.3 Morphological analysers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>, in the
<span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure a descriptive language model can be turned into
a normative one by way of FST filtering: removing all strings tagged as
non-normative. This makes it easy to create acceptors for spelling checkers.
Modelling typical spelling errors is also done using FST’s, with a default setup
that should give reasonable suggestion quality out of the box, but with great
flexibility and possibilities for fine-tuning and alternative ways of building
error models.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p class="ltx_p">The <span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure also includes a fast implementation of a
speller engine using FST’s (the acceptor and the error model), and integration
with the most popular operating systems and office packages. Combined with a
distribution and update tool called
<a href="https://github.com/divvun/?q=pahkat" title="" class="ltx_ref ltx_href ltx_font_italic">pahkat</a> as well as
continuous integration and delivery, it is possible to develop, test and deliver
spellers to the language community with very short cycles. This allows for a
good feedback cycle between the language community and the developers of the
spelling checker, where the community members can see that their feedback is
acted upon, and new updates available in short time.</p>
</div>
<div id="S3.SS6.p3" class="ltx_para">
<p class="ltx_p">The rule-based framework allows building high quality spellers even without
digital data resources. It should also be pointed out that reusing a language
model as a spelling checker would not have been possible using a non-rule-based
framework.</p>
</div>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Grammar checkers</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p class="ltx_p">Since 2019 the <span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure supports building grammar
checkers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib287" title="Many shades of grammar checking – launching a constraint grammar tool for North Sámi" class="ltx_ref">31</a>]</cite>. The grammar checker setup is chaining together
several of the modules described above into a pipeline, roughly as follows:
<span class="ltx_text ltx_font_typewriter">tokenisation &amp; analysis</span> ⇒ <span class="ltx_text ltx_font_typewriter ltx_font_italic">Multiword expression<span class="ltx_text ltx_font_upright"> (MWE)
disambiguation</span></span> ⇒ <span class="ltx_text ltx_font_typewriter">spellchecking of unknowns</span> ⇒ <span class="ltx_text ltx_font_typewriter">disambiguation</span> ⇒
<span class="ltx_text ltx_font_typewriter">error detection</span> ⇒ <span class="ltx_text ltx_font_typewriter">error correction</span>. The main technologies used
are <span class="ltx_text ltx_font_typewriter">hfst-tokenise</span>, VISLCG3 and our spelling checkers.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p class="ltx_p">Evaluations of different error types show good results of the North Sámi grammar
checker <span class="ltx_text ltx_font_italic">GramDivun</span>. Compound error correction reaches a precision of
81.0 Regression tests give up to 88.8 The framework for the grammar checker is
Constraint Grammar <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="Constraint grammar as a framework for parsing unrestricted text" class="ltx_ref">13</a>, <a href="#bib.bib57" title="Constraint grammar manual: 3rd version of the CG formalism variant" class="ltx_ref">7</a>]</cite>.
Constraint Grammar as a rule-based approach is a very good fit as it</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p class="ltx_p">allows partial parses, unfinished disambiguation, and is robust against
remaining ambiguities. In addition, the rule-based approach makes it possible to
build grammar checkers for languages with no or very little digital resources.</p>
</div>
</section>
<section id="S3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.8 </span>Machine translation</h3>

<div id="S3.SS8.p1" class="ltx_para">
<p class="ltx_p">Another high-level tool available within the <span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure is
machine translation. It works in cooperation with the
<a href="https://github.com/apertium" title="" class="ltx_ref ltx_href ltx_font_italic">Apertium</a>
infrastructure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="Recent advances in Apertium, a free/open-source rule-based machine translation platform for low-resource languages" class="ltx_ref">16</a>]</cite>, which is also largely rule-based and
FST-based. The monolingual resources are developed within the <span class="ltx_text ltx_font_italic">GiellaLT</span>
infrastructure, using the same morphological analysers as for other tools, but
slightly tweaked to match the requirements in Apertium. The output is a set of
FST’s made available to Apertium, which contain the bilingual resources for a
given language pair.</p>
</div>
<div id="S3.SS8.p2" class="ltx_para">
<p class="ltx_p">This has resulted in systems with Word Error Rates as good as 0.11 (cf.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="Machine translation with North Saami as a pivot language" class="ltx_ref">1</a>]</cite>, for North to Inari Sámi). The North Sámi to Norwegian
<span class="ltx_text ltx_font_italic">Machine Translation</span> (MT) system delivers close to 1,000 translations a
day<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>
              <span class="ltx_tag ltx_tag_note">2</span>
              
              
              
            <a href="http://jorgal.uit.no/" title="" class="ltx_ref ltx_href">jorgal.uit.no/</a>. The system is
documented at
<a href="https://giellalt.github.io/mt/MachineTranslation.html" title="" class="ltx_ref ltx_href">giellalt.github.io/mt/MachineTranslation.html</a>.</span></span></span>
(cf. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="Med et tastetrykk. bruk av digitale ressurser for samiske språk" class="ltx_ref">2</a>, p. 60]</cite>).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Corpus — Three test cases</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">This section deals with building and handling corpus in the <span class="ltx_text ltx_font_italic">GiellaLT</span>
infrastructure. The question of big data is usually not addressed in articles
that use the data for their machine learning approaches without creating the
data. However, when calculating time-efficiency of the approach, this should be
part of the equation. With our three test cases, we illuminate the actual work
behind an adequate corpus for a certain tool and the challenges behind the
corpus work. Building a corpus with good quality requires selecting native
language texts from different domains, marking up a corpus to make it multi-use,
and also building a special-purpose corpus (i.e. for speech technology) from
scratch.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Collecting corpus texts</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">With our infrastructure, it is possible to build tools without corpora but with
the help of native speakers. With curated corpora, we can verify that our tools
work on a wide range of real-world linguistic phenomena.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p">We have collected corpora for five of the Sámi languages: North, Lule, South,
Inari and Skolt Sámi as well as for 13 other circumpolar languages. The Sámi
corpus is owned by the Norwegian Sámi parliament, and all corpora are
administered and made accessible to the public by the Divvun and Giellatekno
groups. The corpora are split in two based on restrictions set by the copyright
owners. Researchers and anyone else can freely download the free part. The whole
corpus, also the restricted part, is accessible via a public search
interface<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>
              <span class="ltx_tag ltx_tag_note">3</span>
              
              
              
            <a href="https://gtweb.uit.no/korp" title="" class="ltx_ref ltx_href">gtweb.uit.no/korp</a> (Sámi),
<a href="https://gtweb.uit.no/f_korp" title="" class="ltx_ref ltx_href">gtweb.uit.no/f_korp</a> (Baltic Finnic and
Faroese), <a href="https://gtweb.uit.no/u_korp" title="" class="ltx_ref ltx_href">gtweb.uit.no/u_korp</a> (other Uralic
languages). Cf. also
<a href="https://giellalt.github.io/ling/corpus_repositories.html" title="" class="ltx_ref ltx_href">More info about
the corpora.</a></span></span></span>. We have written a tool named
<a href="https://github.com/giellalt/CorpusTools" title="" class="ltx_ref ltx_href">CorpusTools</a> to administer,
convert and analyse the corpus texts. Original texts and their metadata are
saved in svn repositories, then converted to a common XML format, to ease
further use of the texts.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p">Texts in Sámi languages are published daily in both media and by public bodies
required to communicate in writing in Sámi. We have written crawlers to ease the
collection of and to maintain consistent metadata about these texts. The
crawlers gather parallel language versions from those sites that have
unambiguous links to such data. Since most of the publishers (typically online)
have to provide their site in both Sámi and the majority languages, and they
provide interlinks between these page, we are able to build up a rather
comprehensive parallel corpus, as well.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p">Having gathered text since 2005, the largest Sámi corpus is the one for North
Sámi, with 38.94 million tokens. The four other Sámi corpora all contain less
than 3 million words.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p class="ltx_p">The North Sámi corpus is a quite big corpus for an indigenous language, but
small compared to majority languages. The respective majority language corpora
contain 18.4 billion words (Norwegian), 13.9 billion tokens (Swedish) and 14.1
billion words (Finnish)<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>
              <span class="ltx_tag ltx_tag_note">4</span>
              
              
              
            For Norwegian, see
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="Operationalizing a national digital library: the case for a Norwegian transformer model" class="ltx_ref">17</a>]</cite>, which presents the corpus
underlying a language model for Norwegian. The Swedish and Finnish corpora are
searchable at <a href="https://spraakbanken.gu.se/korp" title="" class="ltx_ref ltx_href">spraakbanken.gu.se/korp</a>
and <a href="https://korp.csc.fi/korp/" title="" class="ltx_ref ltx_href">korp.csc.fi/korp/</a>, respectively.</span></span></span>. It
goes without saying that corpora containing billions of words offer
possibilities not available to corpora containing millions of words or even
less.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p class="ltx_p">This does not mean that smaller corpora are not useful. To the contrary,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="Med et tastetrykk. bruk av digitale ressurser for samiske språk" class="ltx_ref">2</a>]</cite> show that the South and Skolt Sámi language
communities (constituting less than 500 speakers each) over a 3-month period via
a dictionary interface accessed their respective corpora (containing 1.5 and 0.2
million words, respectively) 47,000 times each. The language community sees the
corpora as useful, despite their small size.</p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p class="ltx_p">We would also like to have a balanced corpus with regard to regional dialects of
the same language. The Sámi languages have a stronger legal protection in Norway
than in Sweden, our corpus therefore consist of more text written in Norway than
in Sweden. This has consequences for some of the tools we are developing, quite
clearly for translation memory, but also to some extent for other types of tools
such as TTS.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para">
<p class="ltx_p">For North Sámi and Norwegian, we have managed to build a parallel corpus
containing 3.9 million words. For the other Sámi languages, the corresponding
pairs contain 230,000 words or fewer. These corpora mainly contain
administrative texts. They may be used as a foundation for vocabulary
development, using word alignment methods developed for phrase-based machine
translation, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="Digging for domain-specific terms in North Saami" class="ltx_ref">10</a>]</cite> or as a source for dictionary
examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="Med et tastetrykk. bruk av digitale ressurser for samiske språk" class="ltx_ref">2</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Corpus mark-up — upgrading a corpus</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p">The next step towards corpus-assisted NLP is its refinement. When we want to
use a corpus for specific tasks, underlying structures need to be made
accessible in addition to raw text. This can be part-of-speech, morphological,
syntactic, semantic, pragmatic information on the one hand, and error mark-up
together with error categorisation and correction, on the other hand.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p">The approaches for these two are contrastive. Part-of-speech (PoS),
morphological, syntactic and semantic mark-up is done automatically by our
rule-based FST and Constraint Grammar analysers and made available to the
language community in the online application <span class="ltx_text ltx_font_italic">Korp</span>. The error mark-up
is done manually serving as a database for testing and evaluating the quality of
our spellcheckers and handwritten grammar checker rules.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p">The earliest manual error mark-up started in 2006 and served as unseen test data
for Lule and North Sámi spellers. It was further used to automatise
spellchecker testing for Greenlandic, Icelandic, and South Sámi.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="A language technology test bench – automatized testing in the Divvun project" class="ltx_ref">21</a>]</cite> describes an initial testbench for spellcheckers, and
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="Improving feedback on l2 misspellings – an fst approach." class="ltx_ref">4</a>]</cite> takes a first step towards a grammar checker testbench by
adding mark-up of real word errors in addition to non-word spelling errors (i.e.
errors that require syntactic context). The L2 corpus of North Sámi has 4,633
words, 800 sentences, 739 misspellings.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p">Today’s version of the marked-up North Sámi corpus (<span class="ltx_text ltx_font_italic">ErrMark-SIKOR</span>) has
182,450 words and contains mostly administrative and news texts, but also a bit
of fiction and the previously mentioned L2 corpus. However, as the rest of the
corpus, it is enhanced by error mark-up for grammatical and formatting errors in
addition to spelling errors.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p">Alternatively, synthetic errors can be created if larger corpora are needed,
e.g. to train neural networks for e.g. grammar checking
modules. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib290" title="Rules ruling neural networks - neural vs. rule-based grammar checking for a low resource language" class="ltx_ref">33</a>]</cite> For a synthetically created corpus
with congruence errors for a neural-network based grammar checker, we generated
20,846,804 sentences and 2,551,236,949 words. The problematic part with a
synthetic corpus is that we cannot rely on it. For the previously mentioned
corpus, even though synthetic errors were inserted carefully (correct forms
replacing incorrect), unexpected homonymies or unclear contexts can lead to the
inserted forms still being correct. This can only be discovered by manual checks
or a rule-based grammar checker. Another problematic issue is that the corpus
will not reflect the actual distribution of errors made in the real world.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p class="ltx_p">The Lule Sámi corpus mark-up started in 2013 with 29,527 words of unpublished
native speakers texts, with 1,505 non-word errors. With a multi-use in mind,
this corpus was proofread and marked up with other error types including 1,322
morpho-syntactic, syntactic and lexical errors.</p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p class="ltx_p">The texts had neither been spellchecked nor proofread. The large part of errors
(altogether 2,827) is probably due to the young written tradition. A standard
had first been established in 1983 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="Hvordan den nyeste nordsamiske rettskrivingen ble til" class="ltx_ref">19</a>]</cite>. This also illustrates the
urgent need for spelling and grammar aiding tools developed within
<span class="ltx_text ltx_font_italic">GiellaLT</span>.</p>
</div>
<div id="S4.SS2.p8" class="ltx_para">
<p class="ltx_p">A systematic error mark-up has originally been developed for spellchecking, but
then been extended to grammatical error mark-up, formatting, punctuation and
more. The goal behind it is the development of a machine-readable multi-purpose
corpus without changing its originality. Important principles are, therefore,
consistent mark-up (in terms of range and error type) and compatibility with our
tools. That means, for example, that if we have listed a lexical item as a
multi-word, we also need to mark it up as a multi-word.</p>
</div>
<div id="S4.SS2.p9" class="ltx_para">
<p class="ltx_p">The error mark-up syntax follows a number of
guidelines<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>
              <span class="ltx_tag ltx_tag_note">5</span>
              
              
              
            <a href="https://giellalt.uit.no/proof/spelling/testdoc/error-markup.html" title="" class="ltx_ref ltx_href">giellalt.uit.no/proof/spelling/testdoc/error-markup.html</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="Test data and testing of spelling checkers" class="ltx_ref">23</a>]</cite>
and applies eight different general error types: orthographic, real word,
morpho-syntactic, syntactic, lexical, formatting, foreign language and
unclassified errors. The error is enclosed in curly brackets, followed by its
correction in another set of curly brackets. The second curly bracket may or
may not include a part-of-speech, morpho-syntactic criteria and a
subclassification of the error type.</p>
</div>
<div id="S4.SS2.p10" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Orthographic errors</em> include non-words only. They are misspellings
confined to single (error) strings, and the traditional speller should detect
them.
</p>
</div>
<div id="S4.SS2.p11" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Real word errors</em> are misspellings that cannot be detected by a
traditional speller, they are seen as errors due to the context in which they
occur.</p>
</div>
<div id="S4.SS2.p12" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Morpho-syntactic errors</em> are case, agreement, tense, mode errors. They
require an analysis of (parts of) the sentence to be detected.</p>
</div>
<div id="S4.SS2.p13" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Syntactic errors</em> (marked by ¥) require a partial or full analysis
of (parts of) the sentence. They include word order errors, compound errors,
missing words, and redundant words.</p>
</div>
<div id="S4.SS2.p14" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Lexical errors</em> include wrong derivations.</p>
</div>
<div id="S4.SS2.p15" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph ltx_font_italic">Foreign language</em> includes words in other languages that do not require a
correction. <em class="ltx_emph ltx_font_italic">Formatting errors</em> include spacing errors in combination with
punctuation.</p>
</div>
<div id="S4.SS2.p16" class="ltx_para">
<p class="ltx_p">In ex. <a href="#S4.SS2" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, the syntactic error is a missing word and the
correction is adding the subjunctive <span class="ltx_text ltx_font_italic">ahte</span> ‘that’.</p>
</div>
<span class="ltx_ERROR undefined">\exg</span>
<div id="S4.SS2.p17" class="ltx_para">
<p class="ltx_p">. Illá {jáhkken}<span class="ltx_text" style="color:#FF0000;">¥{missing<math id="S4.SS2.p17.m1" class="ltx_Math" alttext="|" display="inline"><mo mathcolor="#FF0000" stretchy="false">|</mo></math>jáhkken ahte}</span> lei
duohta.
<br class="ltx_break">hardly think<span class="ltx_text ltx_font_smallcaps">.past.1sg</span> be<span class="ltx_text ltx_font_smallcaps">.past.3Sg</span> true
<br class="ltx_break">‘I hardly thought that it was true.’</p>
</div>
<div id="S4.SS2.p18" class="ltx_para">
<p class="ltx_p">Regarding the span of an error, we typically mark as little as possible, even if
larger parts of the sentence are responsible for the identification of the
error.</p>
</div>
<div id="S4.SS2.p19" class="ltx_para">
<p class="ltx_p">This is done to facilitate matching error mark-up with grammar checker marking
of the error, and it has a direct effect on automatic evaluation. Most of the
frameworks we use to process language material in context, e.g. Constraint
Grammar, take a token-based approach to language processing, and therefore
marking several words can get cumbersome and should be avoided if possible.</p>
</div>
<div id="S4.SS2.p20" class="ltx_para">
<p class="ltx_p">The marking of errors has had consequences beyond of what we had originally
envisioned. Not only has it resulted in a corpus that can be used in automatic
evaluation of our tools, it has also forced us to categorise errors according to
the underlying principles of the spelling and grammar checker, which had not
necessarily been the same ones a linguist would see in the first place. It
became apparent that grammatical errors marked-up before we started working on a
grammar checker needed to be recategorised, and their span needed to be
shortened. The biggest challenge in marking up a corpus has been consistency,
i.e. the same type of error should always be marked in the same way. In
addition, marking errors should follow the same pattern in all languages in the
<span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure. The mark-up process resulted in an overview
of challenges native speakers have with the written languages, which can help to
improve literacy education in school <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="Improving feedback on l2 misspellings – an fst approach." class="ltx_ref">4</a>]</cite>. It also
revealed where the written language lacks writing rules and norms, which could
then be passed on to <span class="ltx_text ltx_font_italic">Giellagálldo</span>, the normative organ for the Sámi
languages.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Speech corpora and Text-To-Speech</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p">A TTS tool is made to be able to synthesise intelligible speech output from any
unseen text input in a particular language. The main objective for developing
speech technology tools for indigenous languages is to meet the needs of modern
language users in all language communities equally. For the Sámi languages, this
would mean equal possibilities to use Sámi in the same contexts as the majority
languages. In this way, developing speech and language technology tools for the
Sámi languages also contribute to the revitalisation of these languages.
Additionally, speech technology tools are useful for many users, also those with
special needs. These include language learners <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib295" title="Speech technologies applied to second language learning. A use case on Bulgarian. Bachelor’s thesis." class="ltx_ref">35</a>]</cite>, people
with dyslexia, vision impaired individuals, and speakers of the language that
are not used to read it.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p class="ltx_p">Developing TTS for an indigenous language with few resources available can be
challenging. Any linguistic description, grammar or language learning material
is useful, but for speech technology purposes, it is important to have at least
some amount of speech material and corresponding text, provided by a native
speaker of the language. In this way, it is possible to study the relationship
between text and speech in a particular language and to produce a phonetic
description in a form of a grapheme-to-phoneme mapping. This mapping (or
<span class="ltx_text ltx_font_italic">text-to-IPA</span> rule set) can already be used to build a very simple and
“old-fashioned” but still usable TTS application, such as
<a href="https://github.com/espeak-ng" title="" class="ltx_ref ltx_href">the espeak formant
synthesis</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="The opportunity of using espeak as text-to-speech synthesizer for Albanian language" class="ltx_ref">15</a>, <a href="#bib.bib213" title="Adding Japanese language synthesis support to the espeak system" class="ltx_ref">26</a>]</cite>. As this framework
does not require a speech corpus but only a set of phonetic and phonological
rules, any language can be added to the list of the languages covered by
<span class="ltx_text ltx_font_typewriter">espeak</span>, only utilising the knowledge of native speakers.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Building a speech corpus</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p">The modern approaches to TTS involve machine learning and complex modelling of
speech, which brings in the requirement for big amounts of speech data to build
the models from, ideally covering all phonological contrasts and sound
combinations (diphones, triphones) in a given language. This is because in a
data-driven or <span class="ltx_text ltx_font_italic">corpus-based</span> speech synthesis developed that utilize
deep neural networks, the association between textual features and acoustic
parameters is learned directly from paired data—the sentence-long sound files
and the corresponding texts. The sum of the learned knowledge from the paired
data construct the acoustic model (see, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib281" title="From hmms to dnns: where do the improvements come from?" class="ltx_ref">30</a>]</cite>).</p>
</div>
<div id="S4.SS3.SSS1.p2" class="ltx_para">
<p class="ltx_p">The building of the speech corpus starts from collecting a suitable text corpus
which corresponds to at least 10 hours of recorded read speech, that has been
shown to be enough to achieve an end-user suitable
<a href="https://github.com/divvun/lang-sme-ml-speech" title="" class="ltx_ref ltx_href">TTS system for North
Sámi</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="SPEECH synthesis and recognition for a low-resource language: connecting TTS and ASR for mutual benefit" class="ltx_ref">20</a>]</cite>. In Divvun, we focus on open-source
methodologies, in which case it is important to build a collection of open
source texts, with a CC-BY (Creative Commons) licence.</p>
</div>
<div id="S4.SS3.SSS1.p3" class="ltx_para">
<p class="ltx_p">For our on-going Lule Sámi TTS project we reused a part of a Lule Sámi gold
corpus from 2013, and collected additional texts we knew to be well written and
already proofread, before proofreading these texts once more to avoid confusion
when reading the text aloud.</p>
</div>
<div id="S4.SS3.SSS1.p4" class="ltx_para">
<p class="ltx_p">We collected and constructed a Lule Sámi text corpus consisting of various text
styles (news, educational, parliament etc.) with altogether over 74,000 words.
This will approximately correspond to 12 hours of speech recordings when read
aloud by professional voice talents.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Text processing</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p">Most orthographies are underspecified with respect to the pronunciation. This
creates interesting questions when converting a standard orthographic text to
audio waves. In the cases of Lule and North Sámi there is a class of nouns where
consonant gradation (i.e. length alternation) is not expressed in the
orthography, while still being grammatically crucial, as it is the sole marker
of the difference between different syntactic functions, especially
<span class="ltx_text ltx_font_italic">singular nominative</span> vs <span class="ltx_text ltx_font_italic">singular genitive</span>, and for North Sámi
also <span class="ltx_text ltx_font_italic">singular accusative</span>. That is, for this class of nouns the only
difference between the subject and the possessor or between the subject and the
object, is expressed through a length distinction that is <span class="ltx_text ltx_font_italic">not</span> present
in the standard orthography, as seen in
Tables <a href="#S4.T2" title="Table 2 ‣ 4.3.2 Text processing ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S4.T3" title="Table 3 ‣ 4.3.2 Text processing ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. That distinction has to be
recreated when converting the orthographic text to a phonemic representation.
There are other underspecifications in the orthography, but these are the most
crucial.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left">Orth.</td>
<td class="ltx_td ltx_align_left">IPA</td>
<td class="ltx_td ltx_align_left">Transl.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">
<span class="ltx_ERROR undefined">\toprule</span><span class="ltx_text" style="font-size:80%;">Q3</span>
</td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">oarre</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>Po͡Ar:rIE]</td>
<td class="ltx_td ltx_align_left">‘a squirrel’
<span class="ltx_text ltx_font_smallcaps">Nom.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="font-size:80%;">Q2</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">oarre</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>PoAr:IE]</td>
<td class="ltx_td ltx_align_left">‘a squirrel’s’
<span class="ltx_text ltx_font_smallcaps">Gen.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left">‘a reason’ <span class="ltx_text ltx_font_smallcaps">Nom.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="font-size:80%;">Q1</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">oare</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>PoArIE]</td>
<td class="ltx_td ltx_align_left">‘a reason’s’
<span class="ltx_text ltx_font_smallcaps">Gen.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_ERROR undefined">\bottomrule</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ternary length contrast of consonants in Lule Sámi, underspecified in
the orthography. Abbreviations: Q3—overlong, Q2—long, Q1—short.
Originally presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="Quantity contrast in Lule Saami: a three-way system" class="ltx_ref">8</a>]</cite>.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left">Orth.</td>
<td class="ltx_td ltx_align_left">IPA</td>
<td class="ltx_td ltx_align_left">Transl.</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">
<span class="ltx_ERROR undefined">\toprule</span><span class="ltx_text" style="font-size:80%;">Q3</span>
</td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">beassi</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>pe͡æs:sI]</td>
<td class="ltx_td ltx_align_left">‘birchbark’
<span class="ltx_text ltx_font_smallcaps">Nom.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="font-size:80%;">Q2</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">beassi</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>peæs:I]</td>
<td class="ltx_td ltx_align_left">‘birchbark’
<span class="ltx_text ltx_font_smallcaps">Acc.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td ltx_align_left">‘(bird’s)
nest’ <span class="ltx_text ltx_font_smallcaps">Nom.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_text" style="font-size:80%;">Q1</span></td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_italic">beasi</span></td>
<td class="ltx_td ltx_align_left">[<span class="ltx_ERROR undefined">\textipa</span>peæsI]</td>
<td class="ltx_td ltx_align_left">‘(bird’s)
nest’ <span class="ltx_text ltx_font_smallcaps">Acc.Sg</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><span class="ltx_ERROR undefined">\bottomrule</span></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
<td class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ternary length contrast of consonants in North Sámi, underspecified in
the orthography. Abbreviations as in
Table <a href="#S4.T2" title="Table 2 ‣ 4.3.2 Text processing ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</figcaption>
</figure>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p class="ltx_p">The length contrast is encoded in the FST model at an intermediate level, but
during compilation, this information is lost. We have enhanced the
<span class="ltx_text ltx_font_typewriter">hfst-pmatch</span> code to allow the analyser/tokeniser FST to be an
on-the-fly composition of two separate FST’s, and outputting that intermediate
string representation, in effect creating a fake three-tape FST.</p>
</div>
<div id="S4.SS3.SSS2.p3" class="ltx_para">
<p class="ltx_p">With the morphological analysis of all tokens available, we can proceed by
disambiguating the sentence, and leaving only the analyses that fit the
morphosyntactic context. The end result is that we will be left with the proper
analysis (subject or object) <span class="ltx_text ltx_font_italic">and</span> with information of the proper length
of the word form, to be fed to the module for conversion to IPA. As always,
this is done using rule-based components, so we have full control of every step
and are able to correct errors in the IPA transcription. There is still a
fallback module for cases of unknown words and names.</p>
</div>
<div id="S4.SS3.SSS2.p4" class="ltx_para">
<p class="ltx_p">The IPA transcription provided by the FST technology described above can further
improve the accuracy of the TTS, especially the alignment between sounds and
characters. When training a speech model with the IPA transcriptions as text
input (instead of standard orthography) in a deep neural network structure, the
letter-to-sound correspondence will likely be more transparent, also with the
ternary quantity cases described above.</p>
</div>
<div id="S4.SS3.SSS2.p5" class="ltx_para">
<p class="ltx_p">The rule-based approach, reusing many components from other parts of the
<span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure, also means that high quality speech synthesis
is within reach for most language communities.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Approaches to Text-to-Speech</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p class="ltx_p">We have experimented with two different open source TTS methodologies:
<a href="https://github.com/CSTR-Edinburgh/Ossian" title="" class="ltx_ref ltx_href">Ossian</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib249" title="The simple4all entry to the blizzard challenge 2014" class="ltx_ref">28</a>]</cite>
and a Tacotron implementation (largely based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib241" title="Natural tts synthesis by conditioning wavenet on mel spectrogram predictions" class="ltx_ref">27</a>]</cite>),
specially adapted for low-resource languages, like the Sámi
languages <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="SPEECH synthesis and recognition for a low-resource language: connecting TTS and ASR for mutual benefit" class="ltx_ref">20</a>]</cite>.
</p>
</div>
<div id="S4.SS3.SSS3.p2" class="ltx_para">
<p class="ltx_p">In our experiments, we used a data set consisting of approximately one hour of
speech from a native speaker of Lule Sámi, producing nearly intelligible speech.</p>
</div>
<div id="S4.SS3.SSS3.p3" class="ltx_para">
<p class="ltx_p">It is clear that for getting better results, at least 10 hours of training data
would be needed, but piloting the methods using small experimental data gives us
better insight on the requirements for the speech corpus, i.e. the size and
audio quality of the data.</p>
</div>
<div id="S4.SS3.SSS3.p4" class="ltx_para">
<p class="ltx_p">As the expectations for the quality of TTS are very high due to the examples
from well-resourced languages such as English, using a neural vocoder (such as
<span class="ltx_text ltx_font_italic">WaveNet</span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="Wavenet: a generative model for raw audio" class="ltx_ref">24</a>]</cite>) that produces realistic, human-like
speech is necessary for good usability and user experience. One should not
forget that the environmental cost for complex modelling of speech is
high <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="SPEECH synthesis and recognition for a low-resource language: connecting TTS and ASR for mutual benefit" class="ltx_ref">20</a>]</cite>, but it is possible to adapt existing speech
models by training the models further with additional data and pre-trained
models from a “neighbouring” language. This so-called <span class="ltx_text ltx_font_italic">transfer
learning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib258" title="End-to-end text-to-speech for low-resource languages by cross-lingual transfer learning" class="ltx_ref">29</a>]</cite> allows for utilising smaller data sets for training,
making it possible to use e.g. the North Sámi TTS model as the starting point
for the Lule Sámi TTS.</p>
</div>
</section>
<section id="S4.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4 </span>Future work: approaches to automatic speech recognition</h4>

<div id="S4.SS3.SSS4.p1" class="ltx_para">
<p class="ltx_p">In addition to TTS, we are working towards developing a tool for
<span class="ltx_text ltx_font_italic">automatic speech recognition</span> (ASR) for Sámi. In
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="SPEECH synthesis and recognition for a low-resource language: connecting TTS and ASR for mutual benefit" class="ltx_ref">20</a>]</cite>, TTS and ASR models were trained simultaneously in
a dual transformation loop, using the same <span class="ltx_text ltx_font_italic">read speech</span> data set,
corresponding to only six hours of speech from two speakers, three hours each.
The model was trained for 30 000 steps and for the evaluation of the model, it
reached a WER (Word-Error-Rate) of 41</p>
</div>
<div id="S4.SS3.SSS4.p2" class="ltx_para">
<p class="ltx_p">One of the most important differences between training the TTS and ASR models
would be that for TTS, the training material needs to be very clean in terms of
sound quality and there needs to be as many recordings from a single speaker as
possible. For ASR, on the other hand, the recorded materials can be of poorer
sound quality and preferably from multiple speakers and from different areal
varieties of a language as long as there are good transcriptions of the speech.</p>
</div>
<div id="S4.SS3.SSS4.p3" class="ltx_para">
<p class="ltx_p">State-of-the-art ASR frameworks normally require up to 10,000 hours of
multi-speaker data for training reliable and universal models that are able to
generalise to any unseen speaker <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="Deep speech: scaling up end-to-end speech recognition" class="ltx_ref">11</a>]</cite>. As collecting these
amounts of data from small minority languages is not a realistic goal,
alternatives such as utilising existing archive materials can be considered for
developing speech technology for Sámi. These are provided by, e.g.,
<a href="https://www.kielipankki.fi/language-bank/" title="" class="ltx_ref ltx_href ltx_font_italic">The language bank of
Finland</a> and
<a href="https://www.nb.no/sprakbanken/en/resource-catalogue/oai-tekstlab-uio-no-lia-sapmi/" title="" class="ltx_ref ltx_href ltx_font_italic">The language bank of Norway</a>. As these archive materials contain spontaneous,
transcribed spoken materials from various dialects of North Sámi, we are able to
significantly improve the WER of our North Sámi ASR.</p>
</div>
<div id="S4.SS3.SSS4.p4" class="ltx_para">
<p class="ltx_p">In summary, the procedures and pipelines described above could be applied to any
(minority) language with a low-resource setting, in the task of developing
speech technology applications. Most of the applications discussed here can be
piloted with or further developed with relatively small data sets (even with ¡
10 hrs of paired data), compared to the amounts of data used for respective
tools for majority languages. This is largely possible thanks to the available
open source materials and technologies, especially those relying on, e.g.,
<span class="ltx_text ltx_font_italic">transfer learning</span>.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion: Big Data</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">As the previous test cases have shown, big data in terms of large amounts of
data of good quality cannot be assumed in a minority language context. One can
probably go as far as saying that it cannot be expected in any context except
the few big (written) languages. However, big data is usually assumed to just be
available when doing a scientific study or developing language technology tools,
and the judgement “too little data” can mercilessly decide over the
construction of an MT program, inclusion in predominant writing programs (MS
Word etc) as well as whole platforms (Android, iOS).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p">The often heard question of “why not just train a neural model” can usually
readily be answered by the lack of data and also the quality of the data for a
given task, for example grammatically perfect language data when training a
neural model for grammar correction. The lower bounds of required data have been
the centre of machine learnt NLP research in recent years. For example, for
morphology, the annual SIGMORPHON task has found that a machine learnt model can
learn to fill in dictionary inflection tables from just 200,000 gold annotated
examples at 20  In machine translation, similar results have been shown in WMT
shared task on <span class="ltx_text ltx_font_italic">very low resource MT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="Findings of the WMT 2020 shared tasks in unsupervised MT and very low resource supervised MT" class="ltx_ref">9</a>]</cite>, where
it is shown that 60,000 aligned sentences is sufficient for MT between
high-resource and low-resource language, in the example German-Sorbian. Similar
studies exist for many of the fields of NLP, but the general point is that one
still needs tens to hundreds of thousands of annotated, aligned, and
representative samples to even begin.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">In this article we have presented our rule-based tools in the <span class="ltx_text ltx_font_italic">GiellaLT</span>
multilingual infrastructure built during the last 20 years. The
<span class="ltx_text ltx_font_italic">GiellaLT</span> infrastructure contains building blocks and support for most
of the language technology needs of indigenous and minority languages, from the
very basic input technologies like keyboards to high-level advanced tools like
world-class grammar checking and machine translation. It does this by using
rule-based technologies that makes it possible for any language community to get
the language technology tools they want and need. All that is needed is a
linguist.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p">Secondly, we discussed the question of costless and efficient corpus-based
machine learning models for building NLP tools needed by a language community
(keyboards, spell and grammar checkers, machine translation and Text-to-Speech
tools) and also presented an alternative to these models.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p class="ltx_p">We have illustrated the challenges and efforts in collecting good quality native
speaker texts and making them digitally available, as well as further marking up
the corpus texts in a consistent way in order to use them for NLP tasks such as
spelling and grammar checking.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p class="ltx_p">Multi-billion word corpora are the result of decades of work by countless
authors, proof-readers and publishers. For most languages, these resources do
not exist, and relying upon them for making language models will in practice
exclude the vast majority of languages from getting high-quality tools.
Secondly, when corpora exist, they are too dispersed to constitute a foundation
for normative language models. For certain tasks like TTS, if a speech corpus
must be built from scratch, it has to be designed to prioritise quality over
quantity of the corpus. We ensure a good quality and multi-purpose speech corpus
by working with professional voice talents and language experts that are native
speakers of the language.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p class="ltx_p">In conclusion, building corpora is based on big efforts, requires expertise and
is time-costly. We have illuminated the work behind three important steps within
building corpora - firstly, collecting and digitalising, secondly upgrading,
i.e. adding annotation for special purposes, and proofreading, and thirdly
converting from one medium/language to another as in recording speech,
translating, or other.</p>
</div>
<div id="S6.p6" class="ltx_para">
<p class="ltx_p">So, for machine learning approaches that simply make use of existing corpora,
this work does not come for free, it simply has been done by others.</p>
</div>
<div id="S6.p7" class="ltx_para">
<p class="ltx_p">With our multilingual infrastructure and our language resources we show that
while there is a need for corpus data for certain tasks, high quality tools
needed by a language community can be built time-efficiently without big data in
a rule-based manner.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Bibliographical References</h2>

</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="bib.L1" class="ltx_biblist">
<li id="bib.bib15" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Antonsen, C. Gerstenberger, M. Kappfjell, S. Ráhka, M.-L. Olthuis, T. Trosterud, and F. M. Tyers</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Machine translation with North Saami as a pivot language</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 21st Nordic Conference on Computational Linguistics, NoDaLiDa</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 123–131</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS8.p2" title="3.8 Machine translation ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.8</span></a>.
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inbook">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Antonsen and T. Trosterud</span><span class="ltx_text ltx_bib_year"> (2020)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Med et tastetrykk. bruk av digitale ressurser for samiske språk</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">Samiske tall forteller. Kommentert samisk statistikk</span>, Vol. <span class="ltx_text ltx_bib_volume">12</span>, <span class="ltx_text ltx_bib_pages"> pp. 43–68</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS8.p2" title="3.8 Machine translation ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.8</span></a>,
<a href="#S4.SS1.p6" title="4.1 Collecting corpus texts ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.1</span></a>,
<a href="#S4.SS1.p8" title="4.1 Collecting corpus texts ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.1</span></a>.
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Antonsen, L. Wiechetek, and T. Trosterud</span><span class="ltx_text ltx_bib_year"> (2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Reusing grammatical resources for new languages</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Stroudsburg</span>, <span class="ltx_text ltx_bib_pages"> pp. 2782–2789</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.p5" title="3.1 The GiellaLT infrastructure ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.1</span></a>.
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Antonsen</span><span class="ltx_text ltx_bib_year"> (2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Improving feedback on l2 misspellings – an fst approach.</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the SLTC 2012 workshop on NLP for CALL</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Lund</span>, <span class="ltx_text ltx_bib_pages"> pp. 11–10</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.p20" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>,
<a href="#S4.SS2.p3" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Ardila, M. Branson, K. Davis, M. Henretty, M. Kohler, J. Meyer, R. Morais, L. Saunders, F. M. Tyers, and G. Weber</span><span class="ltx_text ltx_bib_year"> (2019)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Common voice: a massively-multilingual speech corpus</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">arXiv preprint arXiv:1912.06670</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p2" title="2.2 Related work ‣ 2 Background ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2.2</span></a>.
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem ltx_bib_book">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. R. Beesley and L. Karttunen</span><span class="ltx_text ltx_bib_year"> (2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finite state morphology</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">CSLI publications</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-1575864341</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p1" title="3.3 Morphological analysers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>.
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem ltx_bib_manual">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Didriksen</span><span class="ltx_text ltx_bib_year"> (2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Constraint grammar manual: 3rd version of the CG formalism variant</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">GrammarSoft ApS</span>, <span class="ltx_text ltx_bib_place">Denmark</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://visl.sdu.dk/cg3/vislcg3.pdf%20(Accessed%202017-11-29)" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS4.p1" title="3.4 Morphological and syntactic disambiguation and tagging ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.4</span></a>,
<a href="#S3.SS7.p2" title="3.7 Grammar checkers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.7</span></a>.
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">N. Fangel-Gustavson, R. Ridouane, and B. Morén-Duolljá</span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Quantity contrast in Lule Saami: a three-way system</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 10th International Seminar on Speech production</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 106–109</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.T2" title="Table 2 ‣ 4.3.2 Text processing ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>.
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Fraser</span><span class="ltx_text ltx_bib_year"> (2020-11)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Findings of the WMT 2020 shared tasks in unsupervised MT and very low resource supervised MT</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Fifth Conference on Machine Translation</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Online</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://aclanthology.org/2020.wmt-1.80" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.p2" title="5 Discussion: Big Data ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§5</span></a>.
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Gerstenberger, B. M. N. Eskonsipo, and M. Eira</span><span class="ltx_text ltx_bib_year"> (2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Digging for domain-specific terms in North Saami</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">Oovtast conference</span>, <span class="ltx_text ltx_bib_place">Inari</span>.
</span>
<span class="ltx_bibblock">Note: <span class="ltx_text ltx_bib_note">Conference presentation at Oovtast conference, Inari</span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p8" title="4.1 Collecting corpus texts ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.1</span></a>.
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates, <span class="ltx_text ltx_bib_etal">et al.</span></span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Deep speech: scaling up end-to-end speech recognition</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">arXiv preprint arXiv:1412.5567</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS4.p3" title="4.3.4 Future work: approaches to automatic speech recognition ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.4</span></a>.
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Hulden</span><span class="ltx_text ltx_bib_year"> (2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Foma: a finite-state compiler and library</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Demonstrations Session at EACL 2009</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 29–32</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p1" title="3.3 Morphological analysers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>.
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">F. Karlsson</span><span class="ltx_text ltx_bib_year"> (1990)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Constraint grammar as a framework for parsing unrestricted text</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 13th International Conference of Computational Linguistics</span>,  <span class="ltx_text ltx_bib_editor">H. Karlgren (Ed.)</span>,
</span>
<span class="ltx_bibblock">Vol. <span class="ltx_text ltx_bib_volume">3</span>, <span class="ltx_text ltx_bib_place">Helsinki</span>, <span class="ltx_text ltx_bib_pages"> pp. 168–173</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS4.p1" title="3.4 Morphological and syntactic disambiguation and tagging ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.4</span></a>,
<a href="#S3.SS7.p2" title="3.7 Grammar checkers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.7</span></a>.
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Karttunen</span><span class="ltx_text ltx_bib_year"> (2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Beyond morphology: pattern matching with fst</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">International Workshop on Systems and Frameworks for Computational Morphology</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1–13</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS5.p1" title="3.5 Tokenisers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.5</span></a>.
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Kastrati, M. Hamiti, and L. Abazi</span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The opportunity of using espeak as text-to-speech synthesizer for Albanian language</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 15th International Conference on Computer Systems and Technologies</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 179–186</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.p2" title="4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3</span></a>.
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Khanna, J. N. Washington, F. M. Tyers, S. Bayatlı, D. Swanson, F. Pirinen, I. Tang, and H. Alos i Font</span><span class="ltx_text ltx_bib_year"> (2021-10)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Recent advances in Apertium, a free/open-source rule-based machine translation platform for low-resource languages</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Machine Translation</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://dx.doi.org/10.1007/s10590-021-09260-6" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p1" title="2.2 Related work ‣ 2 Background ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2.2</span></a>,
<a href="#S3.SS8.p1" title="3.8 Machine translation ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.8</span></a>.
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. E. Kummervold, J. De la Rosa, F. Wetjen, and S. A. Brygfjeld</span><span class="ltx_text ltx_bib_year"> (2021)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Operationalizing a national digital library: the case for a Norwegian transformer model</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Reykjavik, Iceland (Online)</span>, <span class="ltx_text ltx_bib_pages"> pp. 20–29</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://aclanthology.org/2021.nodalida-main.3" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#footnote4" title="footnote 4 ‣ 4.1 Collecting corpus texts ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">footnote 4</span></a>.
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Lindén, E. Axelson, S. Drobac, S. Hardwick, J. Kuokkala, J. Niemi, T. A. Pirinen, and M. Silfverberg</span><span class="ltx_text ltx_bib_year"> (2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Hfst—a system for creating nlp tools</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">International workshop on systems and frameworks for computational morphology</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 53–71</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p1" title="3.3 Morphological analysers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>.
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">O. H. Magga</span><span class="ltx_text ltx_bib_year"> (1994)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Hvordan den nyeste nordsamiske rettskrivingen ble til</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Festskrift til Ørnulv Vorren</span>, <span class="ltx_text ltx_bib_pages"> pp. 269–282</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.p7" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Makashova</span><span class="ltx_text ltx_bib_year"> (2021)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">SPEECH synthesis and recognition for a low-resource language: connecting TTS and ASR for mutual benefit</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">University of Gothenburg</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS1.p2" title="4.3.1 Building a speech corpus ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.1</span></a>,
<a href="#S4.SS3.SSS3.p1" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>,
<a href="#S4.SS3.SSS3.p4" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>,
<a href="#S4.SS3.SSS4.p1" title="4.3.4 Future work: approaches to automatic speech recognition ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.4</span></a>.
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. N. Moshagen</span><span class="ltx_text ltx_bib_year"> (2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A language technology test bench – automatized testing in the Divvun project</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the Workshop on NLP for Reading and Writing – Resources, Algorithms and Tools</span>,  <span class="ltx_text ltx_bib_editor">R. Domeij, S. J. Kokkinakis, O. Knutsson, and S. S. Hashemi (Eds.)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">NEALT Proceeding Series</span>, <span class="ltx_text ltx_bib_place">Stockholm</span>, <span class="ltx_text ltx_bib_pages"> pp. 19––21</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.p3" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. N. Moshagen, F. Pirinen, and T. Trosterud</span><span class="ltx_text ltx_bib_year"> (2013-05)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Building an open-source development infrastructure for language technology projects</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 19th Nordic Conference of Computational Linguistics (NODALIDA 2013)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Oslo, Norway</span>, <span class="ltx_text ltx_bib_pages"> pp. 343–352</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://www.aclweb.org/anthology/W13-5631" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p1" title="2.2 Related work ‣ 2 Background ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2.2</span></a>.
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Moshagen</span><span class="ltx_text ltx_bib_year"> (2014-11-13)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Test data and testing of spelling checkers</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">UiT Norges arktiske universitet</span>.
</span>
<span class="ltx_bibblock">Note: <span class="ltx_text ltx_bib_note">presentation at the NorWEST2014 workshop</span>
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://divvun.no/events/workshops/NorWEST2014/presentations/Moshagen.pdf" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.p9" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. v. d. Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves, N. Kalchbrenner, A. Senior, and K. Kavukcuoglu</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Wavenet: a generative model for raw audio</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">arXiv preprint arXiv:1609.03499</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS3.p4" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>.
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. A. Pirinen and F. M. Tyers</span><span class="ltx_text ltx_bib_year"> (2021)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Building language technology infrastructures to support a collaborative approach to language resource building</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Multilingual Facilitation</span>, <span class="ltx_text ltx_bib_pages"> pp. 53</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p1" title="2.2 Related work ‣ 2 Background ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2.2</span></a>.
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Pronk, B. O. K. Intelligentie, and D. D. Weenink</span><span class="ltx_text ltx_bib_year"> (2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Adding Japanese language synthesis support to the espeak system</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">University of Amsterdam</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.p2" title="4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3</span></a>.
</span>
</li>
<li id="bib.bib241" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Shen, R. Pang, R. J. Weiss, M. Schuster, N. Jaitly, Z. Yang, Z. Chen, Y. Zhang, Y. Wang, R. Skerrv-Ryan, <span class="ltx_text ltx_bib_etal">et al.</span></span><span class="ltx_text ltx_bib_year"> (2018)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Natural tts synthesis by conditioning wavenet on mel spectrogram predictions</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 4779–4783</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS3.p1" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>.
</span>
</li>
<li id="bib.bib249" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Suni, T. Raitio, D. Gowda, R. Karhila, M. Gibson, and O. Watts</span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The simple4all entry to the blizzard challenge 2014</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proc. Blizzard Challenge</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS3.p1" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>.
</span>
</li>
<li id="bib.bib258" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Tu, Y. Chen, C. Yeh, and H. Lee</span><span class="ltx_text ltx_bib_year"> (2019)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">End-to-end text-to-speech for low-resource languages by cross-lingual transfer learning</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">arXiv preprint arXiv:1904.06508</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS3.p4" title="4.3.3 Approaches to Text-to-Speech ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.3</span></a>.
</span>
</li>
<li id="bib.bib281" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">O. Watts, G. E. Henter, T. Merritt, Z. Wu, and S. King</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">From hmms to dnns: where do the improvements come from?</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 5505–5509</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.SSS1.p1" title="4.3.1 Building a speech corpus ‣ 4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3.1</span></a>.
</span>
</li>
<li id="bib.bib287" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Wiechetek, S. N. Moshagen, B. Gaup, and T. Omma</span><span class="ltx_text ltx_bib_year"> (2019)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Many shades of grammar checking – launching a constraint grammar tool for North Sámi</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the NoDaLiDa 2019 Workshop on Constraint Grammar -
Methods, Tools and Applications</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">NEALT Proceedings Series 33:8</span>, <span class="ltx_text ltx_bib_pages"> pp. 35–44</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS7.p1" title="3.7 Grammar checkers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.7</span></a>.
</span>
</li>
<li id="bib.bib286" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Wiechetek, S. N. Moshagen, and K. B. Unhammer</span><span class="ltx_text ltx_bib_year"> (2019-02)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Seeing more than whitespace — tokenisation and disambiguation in a North Sámi grammar checker</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 3rd Workshop on the Use of Computational
Methods in the Study of Endangered Languages Volume 1 (Papers)</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Honolulu</span>, <span class="ltx_text ltx_bib_pages"> pp. 46–55</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="https://www.aclweb.org/anthology/W19-6007" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS5.p2" title="3.5 Tokenisers ‣ 3 A multilingual infrastructure from scratch ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.5</span></a>.
</span>
</li>
<li id="bib.bib290" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Wiechetek, F. Pirinen, M. Hämäläinen, and C. Argese</span><span class="ltx_text ltx_bib_year"> (2021-09)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Rules ruling neural networks - neural vs. rule-based grammar checking for a low resource language</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.p5" title="4.2 Corpus mark-up — upgrading a corpus ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib294" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Wolf, J. Chaumond, L. Debut, V. Sanh, C. Delangue, A. Moi, P. Cistac, M. Funtowicz, J. Davison, S. Shleifer, <span class="ltx_text ltx_bib_etal">et al.</span></span><span class="ltx_text ltx_bib_year"> (2020)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Transformers: state-of-the-art natural language processing</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing: System Demonstrations</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 38–45</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p2" title="2.2 Related work ‣ 2 Background ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2.2</span></a>.
</span>
</li>
<li id="bib.bib295" class="ltx_bibitem ltx_bib_misc">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Yaneva</span><span class="ltx_text ltx_bib_year"> (2021)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Speech technologies applied to second language learning. A use case on Bulgarian. Bachelor’s thesis.</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">Universitat Pompeu Fabra</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS3.p1" title="4.3 Speech corpora and Text-To-Speech ‣ 4 Corpus — Three test cases ‣ Unmasking the Myth of Effortless Big Data — Making an Open Source Multilingual Infrastructure and Building Language Resources from Scratch 1 footnote 1 1 footnote 1 LREC is open access with CC-BY-NC licence. Print version can be found at https:/2022.lrec-conf.org/" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3</span></a>.
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun 14 13:50:15 2022 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>
